# Following: https://medium.com/data-science-collective/how-to-create-3d-models-from-any-image-with-ai-zero-shot-3d-reconstruction-21d3023ad81b

# Create new environment with Python 3.12
conda create -n map-anything python=3.12 -y

conda activate map-anything

# Find cuda version with nvidia-smi
nvidia-smi

# This gives 12.8, but apparently conda only supports up to 12.4 so far, so grab from online
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Confirm it worked:
python
import torch
print(torch.cuda.is_available())  # Should return True
print(torch.cuda.get_device_name(0))  # Shows GPU

# Clone the repository
git clone https://github.com/facebookresearch/map-anything.git
cd map-anything

# For all optional dependencies
# See pyproject.toml for more details
pip install -e ".[all]"
pre-commit install

# Extra installs
pip install open3d numpy



# OR:
pip install -e ".[colmap]"




Follow the blog up to and including:

“Initialization: Setting Up Your Development Environment”

Do the sub-sections:
“Creating a Clean Anaconda Environment”, “Installing PyTorch with CUDA Support”, “Installing Libraries: MapAnything Framework”, “Installing Other Libraries: Open3D + Numpy” (Open3D isn’t required later, but it won’t hurt).

“Configuring Memory Management and Core Imports”

Keep the PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True" bit.

“Step 1: Device Detection and Hardware Verification”

“Step 2: Loading the MapAnything Model from HuggingFace Hub”

“Step 3: Image Loading and Automatic Preprocessing”

“Step 4: Running Inference with Optimized Parameters”

STOP immediately after the code block that assigns:

predictions = model.infer(...)


You may read the next single line that begins “Access results for each view — Complete list…”, but do not follow any of the per-view extraction that comes after it.

Do NOT follow these blog sections (we switch before them):

“Step 6: Extracting per view 2D / 3Delements” (yes, it’s labelled “Step 6” again in the post)

“Step 6: Decoding Prediction Tensors and Understanding Data Types”

“Step 7: Extracting Valid 3D Points with Mask Filtering”

“Step 8: Mapping RGB Colors from Source Images”

“Step 9: Merging Multi-View Predictions into Complete Reconstruction”

“Step 10: Exporting to Standard 3D Formats”

Those are the parts where the author hand-codes point extraction/merging/export. Skip all of that because we’ll export straight to COLMAP using MapAnything’s built-in scripts.
