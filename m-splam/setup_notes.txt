Note this doc is mainly written by AI for AI to help as context when setting up the env

================================================================================
MASt3R-SLAM INSTALLATION NOTES - Fresh Install Following Official README
================================================================================
Date: November 18, 2025
System: Ubuntu with NVIDIA RTX PRO 6000 Blackwell (sm_120 architecture)
Driver: NVIDIA 580.95.05, CUDA Version: 13.0

================================================================================
OBJECTIVE
================================================================================
Install MASt3R-SLAM following the official README.md instructions, adapting for
our system's unique characteristics (newer GPU, CUDA 13 driver).

================================================================================
SYSTEM CHARACTERISTICS & CHALLENGES
================================================================================
1. GPU: NVIDIA RTX PRO 6000 Blackwell Max-Q (compute capability sm_120)
   - So new that PyTorch 2.5.1 doesn't officially support it
   - Should work but with warnings
   
2. CUDA Driver: 13.0 (via nvidia-smi)
   - No system nvcc installed
   - README offers PyTorch with CUDA 11.8, 12.1, or 12.4
   - We chose CUDA 12.4 (newest available, backward compatible)

3. Previous Attempts:
   - Tried using exported conda environment from different machine
   - Hit numerous CUDA compilation issues with mismatched versions
   - This is a CLEAN START following official README

================================================================================
INSTALLATION STEPS TAKEN
================================================================================

STEP 1: Create Environment
---------------------------
Command: conda create -n mast3r-slam python=3.11 -y
Status: ✓ SUCCESS
Notes: Clean environment with only Python 3.11

STEP 2: Install PyTorch with CUDA 12.4
---------------------------------------
Command: conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 pytorch-cuda=12.4 -c pytorch -c nvidia -y
Status: ✓ SUCCESS (after fix)

ISSUE ENCOUNTERED: iJIT_NotifyEvent Symbol Error
When testing PyTorch import:
  ImportError: undefined symbol: iJIT_NotifyEvent

ROOT CAUSE: 
  - Conda installed MKL 2025.0.0 (newest Math Kernel Library)
  - PyTorch 2.5.1 was compiled against MKL 2023.1.0 (older version)
  - Version mismatch causes missing symbol errors

ATTEMPTED FIX #1 (FAILED):
  - Moved conda's libstdc++.so.6 files to backup
  - This was based on incorrect assumption about the error source
  - Did NOT fix the issue

ACTUAL FIX (WORKED):
  Command: conda install mkl=2023.1.0 mkl-service=2.4.0 intel-openmp=2023.0.0 -y
  - Downgraded MKL to version PyTorch was compiled against
  - Also downgraded: mkl_fft, mkl_random, numpy (to compatible versions)

Verification:
  python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
  Result: PyTorch 2.5.1, CUDA available: True
  Warning: GPU sm_120 not officially supported (expected, will work anyway)

STEP 3: Install MASt3R-SLAM Packages
-------------------------------------
Per README, need to install in order:
  1. pip install --no-build-isolation -e thirdparty/mast3r
  2. pip install -e thirdparty/in3d
  3. pip install --no-build-isolation -e .

CRITICAL ISSUE: CUDA Compiler Version Mismatch
-----------------------------------------------
The 'curope' package (part of mast3r) requires CUDA compilation. Multiple problems:

PROBLEM 1: No system nvcc compiler initially
PROBLEM 2: Conda's CUDA packages default to CUDA 13.x
PROBLEM 3: PyTorch 2.5.1 built with CUDA 12.4
PROBLEM 4: CUDA version mismatch breaks compilation

ATTEMPTED SOLUTIONS (ALL FAILED):
1. Conda-installed CUDA toolkit (gets CUDA 13, incompatible with PyTorch)
2. Force conda to install CUDA 12.4 packages (not available in default channels)
3. Use mamba instead of conda (same problem)

WORKING SOLUTION: System-Wide CUDA 12.4 Installation
-----------------------------------------------------
Strategy: Install CUDA 12.4 toolkit system-wide, point conda environment to it

STEP 3.1: Install System CUDA 12.4
Download and install CUDA 12.4.1 (matches PyTorch):
  cd /tmp
  wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda_12.4.1_550.54.15_linux.run
  sudo sh cuda_12.4.1_550.54.15_linux.run --toolkit --silent --override

Flags explained:
  --toolkit: Only install toolkit, skip driver (we have 13.0 driver, it's fine)
  --silent: No prompts
  --override: Allow installation alongside existing driver

Verification:
  ls /usr/local/ | grep cuda
  Result: cuda, cuda-12.4 (both directories created)
  
  /usr/local/cuda-12.4/bin/nvcc --version
  Result: Cuda compilation tools, release 12.4, V12.4.131

STEP 3.2: Configure Conda Environment to Use System CUDA
Create activation script so CUDA 12.4 is automatically configured:
  mkdir -p ~/miniconda3/envs/mast3r-slam/etc/conda/activate.d/
  
Create file: ~/miniconda3/envs/mast3r-slam/etc/conda/activate.d/cuda.sh
Contents:
  #!/bin/bash
  export CUDA_HOME=/usr/local/cuda-12.4
  export PATH=$CUDA_HOME/bin:$PATH
  export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

Test activation:
  conda deactivate && conda activate mast3r-slam
  echo $CUDA_HOME
  Result: /usr/local/cuda-12.4
  
  nvcc --version
  Result: Cuda compilation tools, release 12.4, V12.4.131 ✓

STEP 3.3: Install Compatible GCC Compiler
curope compilation requires g++, and CUDA 12.4 supports gcc/g++ up to version 13.

ATTEMPT 1 (FAILED): conda install gxx_linux-64 -y
  Result: Installed gcc/g++ 15.2.0
  ERROR: CUDA 12.4 doesn't support gcc > 13
  Error message: "unsupported GNU version! gcc versions later than 13 are not supported!"

SOLUTION: Install gcc/g++ 11.2.0 (compatible with CUDA 12.4)
  conda install gcc_linux-64=11.2.0 gxx_linux-64=11.2.0 -y
  
Verification:
  x86_64-conda-linux-gnu-c++ --version
  Result: g++ (conda-forge gcc 11.2.0-16) 11.2.0

STEP 3.4: Install thirdparty/mast3r
Command: pip install --no-build-isolation -e thirdparty/mast3r
Status: ✓ SUCCESS

Key points:
  - --no-build-isolation: Makes torch available during curope build
  - curope compilation took ~5 minutes (compiling for multiple GPU architectures)
  - Successfully compiled: curope-0.0.0
  - System CUDA 12.4 + gcc 11.2.0 = working combination

Installed packages include:
  - MAST3R-0.0.1
  - curope-0.0.0 (CUDA extension, compiled)
  - asmk-0.1
  - dust3r dependencies: gradio, roma, matplotlib, trimesh, tensorboard, etc.

STEP 3.5: Install thirdparty/in3d
Command: pip install -e thirdparty/in3d
Status: ✓ SUCCESS (with minor warning)

Installed packages include:
  - in3d-0.0.1
  - moderngl, moderngl-window, pyglm, imgui (OpenGL rendering)
  - trimesh extras: manifold3d, shapely, rtree, etc.

WARNING: numpy version conflict
  - opencv-python requires numpy>=2.0
  - in3d dependencies installed numpy 1.26.4
  - This may cause issues, but installation completed

STEP 3.6: Install Main MASt3R-SLAM Package
Command: pip install --no-build-isolation -e .
Status: ✓ SUCCESS

Key installations:
  - MAST3R-SLAM-0.0.1 (main package, editable)
  - lietorch-0.3 (Lie algebra for PyTorch, compiled from GitHub)
  - evo-1.34.0 (trajectory evaluation)
  - pyrealsense2-2.56.5.9235 (RealSense camera support)
  - Plus: seaborn, rosbags, natsort, plyfile, etc.

VERIFICATION: ✓ ALL SUCCESSFUL
Command: python -c "import torch; import curope; import mast3r; import lietorch; print('✓ All critical imports successful')"
Result: All imports work correctly
  - PyTorch: 2.5.1
  - CUDA available: True
  - curope (CUDA extension): Imports successfully
  - mast3r: Imports successfully
  - lietorch: Imports successfully

INSTALLATION COMPLETE!
Status: Core packages installed and verified
Next: Download model checkpoints and test with demo data

================================================================================
LESSONS LEARNED
================================================================================
1. Always follow official README for fresh installs
2. MKL version mismatches cause symbol errors - check PyTorch compatibility
3. Newer GPUs may not be officially supported but often work
4. CUDA version compatibility matters for compilation, not just runtime
5. Don't assume same error = same fix without verification

CRITICAL LESSON: System CUDA vs Conda CUDA
-------------------------------------------
6. For ML projects requiring CUDA compilation (not just runtime):
   - System-wide CUDA installation is the standard approach
   - Conda's CUDA packages are for runtime only (cudatoolkit, pytorch-cuda)
   - Conda cannot reliably separate compiler version from runtime version
   - Installing nvcc via conda often gets wrong/incompatible versions

7. Solution Pattern for Multiple Projects:
   - Install multiple CUDA versions system-wide: /usr/local/cuda-{version}/
   - Create per-environment activation scripts to set CUDA_HOME
   - Each project's conda env points to appropriate CUDA version
   - Pattern: ~/miniconda3/envs/{env_name}/etc/conda/activate.d/cuda.sh
   
8. CUDA Compiler Compatibility:
   - Always check gcc/g++ version compatibility with CUDA version
   - CUDA 12.4 supports gcc up to version 13
   - Use conda to install compatible gcc version for environment
   - Example: conda install gcc_linux-64=11.2.0 gxx_linux-64=11.2.0

9. Installation Order Matters:
   - System CUDA first
   - Conda activation script second
   - Compatible gcc/g++ third
   - Then pip install with --no-build-isolation for packages needing torch

================================================================================
NEXT STEPS
================================================================================
[✓] Install thirdparty/mast3r - COMPLETE
[✓] Install thirdparty/in3d - COMPLETE
[✓] Install main package - COMPLETE
[✓] Verify all imports work - COMPLETE
[ ] Download model checkpoints (3 files from europe.naverlabs.com)
[ ] Test with demo data (TUM RGBD dataset)

Model Checkpoints Required (per README):
  1. MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth
  2. dust3r_vit_large.pth  
  3. sam2.1_hiera_large.pkl

Demo Test Command:
  bash ./scripts/download_tum.sh
  python main.py --dataset datasets/tum/rgbd_dataset_freiburg1_room/ --config config/calib.yaml

================================================================================
REPLICATION GUIDE FOR OTHER PROJECTS
================================================================================
If another project needs CUDA compilation with different CUDA version:

1. Install system CUDA (if not already present):
   wget https://developer.download.nvidia.com/compute/cuda/{VERSION}/local_installers/cuda_{VERSION}_linux.run
   sudo sh cuda_{VERSION}_linux.run --toolkit --silent --override
   
2. Create conda environment:
   conda create -n {project_name} python={version} -y
   conda activate {project_name}
   
3. Install PyTorch matching CUDA version:
   conda install pytorch torchvision torchaudio pytorch-cuda={VERSION} -c pytorch -c nvidia -y
   
4. Create CUDA activation script:
   mkdir -p ~/miniconda3/envs/{project_name}/etc/conda/activate.d/
   cat > ~/miniconda3/envs/{project_name}/etc/conda/activate.d/cuda.sh << 'EOF'
   #!/bin/bash
   export CUDA_HOME=/usr/local/cuda-{VERSION}
   export PATH=$CUDA_HOME/bin:$PATH
   export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
   EOF
   
5. Install compatible gcc (check CUDA documentation for supported versions):
   conda activate {project_name}
   conda install gcc_linux-64={version} gxx_linux-64={version} -y
   
6. Verify setup:
   conda deactivate && conda activate {project_name}
   nvcc --version  # Should show correct CUDA version
   
7. Install packages with CUDA extensions:
   pip install --no-build-isolation -e {package}

================================================================================
