# Pipeline Configuration Template
# Copy this file and customize for each run
# run example command:
# python /home/ben/encode/code/3D-Reefs/m-splam/run_pipeline.py --config /home/ben/encode/code/3D-Reefs/m-splam/slam_splat_config.yaml --only 1

# Unique identifier for this run (used for output directory naming)
run_name: "highres_Mars"

# Pipeline Control
pipeline:
  # Enable step-by-step confirmation (useful for debugging)
  interactive: false
  # Skip completed steps if outputs exist
  skip_existing: false

# Paths 
paths:
  # Raw images (high res, no modifications)
  original_images_path: "/home/ben/encode/data/mars_johns/left"
  # Downsampled images directory (used for SLAM))
  images_path: "/home/ben/encode/data/mars_johns/left_downsampled_png"
  # Directory where intermediate data and outputs will be stored
  intermediate_data_root: "/home/ben/encode/data/intermediate_data"
  # MASt3R-SLAM installation directory
  mast3r_slam_root: "/home/ben/encode/code/MASt3R-SLAM"
  # LichtFeld-Studio binary path
  lichtfeld_binary: "/home/ben/encode/code/lichtfeld-studio/build/LichtFeld-Studio"

# Step 1: COLMAP Intrinsics Estimation (estimate_intrinsics.py)
#TODO: see TODO in pipeline.py about how 100 images might be overkill.
intrinsics_estimation:
  # Number of images to use for calibration
  num_images: 100
  # Camera model: "OPENCV" (GoPro/wide-angle) or "OPENCV_FISHEYE" (extreme fisheye)
  # TODO: should be able to take any standard colmap camera model
  camera_model: "OPENCV"
  # Overwrite existing output without prompting
  overwrite: true

# Step 2: Intrinsics Conversion (shuttle_intrinsics.py)
intrinsics_conversion:
  # Use high-resolution original images for splatting?
  # - true:  Use original high-res images (distorted) → Keeps OPENCV model, scales intrinsics to high-res
  # - false: Use MASt3R-SLAM keyframes (undistorted) → Converts to PINHOLE model, uses SLAM resolution
  # 
  # Technical details:
  # - MASt3R-SLAM outputs undistorted keyframes (~512px width) which are PINHOLE-compatible
  # - Original images retain lens distortion and need OPENCV/FISHEYE model
  # - If true: Also runs convert_intrinsics.py to scale intrinsics from low-res to high-res
  use_highres_for_splatting: true #TODO: move to a global var?
  # run LFS with --gut if using this ^!
  
  # Also save original camera model as cameras_{MODEL}.bin/txt
  keep_original: false

# Step 3: MASt3R-SLAM
mast3r_slam:
  # Config file (relative to mast3r_slam_root or absolute path)
  config: "/home/ben/encode/code/MASt3R-SLAM/config/base.yaml" #"config/base.yaml"
  # Enable visualization (requires manual Ctrl+C to continue pipeline after SLAM completes)
  # Set to false for automated runs. TODO: Run visualization in separate process to avoid blocking.
  enable_visualization: false
  # Additional arguments to pass to MASt3R-SLAM (optional)
  # Example: ["--single_thread"]
  extra_args: []

# Step 4: Pose/Keyframe Conversion (cam_pose_keyframes_shuttle.py)
pose_conversion:
  # Use symlinks instead of copying images (faster, saves space)
  link_images: false
  # Camera ID (null for auto-detect from cameras.txt)
  camera_id: null

# Step 6: PLY to COLMAP points3D (mslam_ply_to_points3d.py)
ply_conversion:
  # Percentage of points to sample (10% = ~500K-1M points)
  # Lower = faster, less memory. Higher = more detail
  sample_percentage: 5.0 #If rerunning, be sure to del or rename the original file, otherwise it will skip this step

# Step 6: Gaussian Splatting Training (train_splat.py)
gaussian_splatting:
  # Run in headless mode (no GUI)
  headless: true
  # Number of training iterations
  iterations: 20000
  # Maximum splat count after densification
  max_cap: 1000000
  # Additional LichtFeld-Studio arguments
  # Example: ["--random", "--save-every", "10000"]
  extra_args: ["--gut"] ############################## BEWARE I HAVE GUT here

